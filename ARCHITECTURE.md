# üèóÔ∏è ARCHITECTURE NETPULSE-AI

## üìê Vue d'ensemble

**NetPulse-AI** est une application full-stack de monitoring de liaisons micro-ondes FH (Faisceaux Hertziens) avec intelligence artificielle.

### Stack technologique
- **Backend** : Python 3.11.9
- **Frontend** : Streamlit 1.51.0 (multi-pages)
- **Base de donn√©es** : MySQL 8.4.3 (Laragon)
- **ORM** : SQLAlchemy 2.0.44 + PyMySQL 1.1.2
- **ML/IA** : Scikit-learn 1.7.2 (Isolation Forest, Linear Regression)
- **Visualisation** : Plotly 6.5.0, Altair 5.5.0

---

## üìÅ Structure des fichiers

```
netpulse-ai/
‚îÇ
‚îú‚îÄ‚îÄ üè† RACINE
‚îÇ   ‚îú‚îÄ‚îÄ app.py                      # Point d'entr√©e principal Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ config.py                   # Configuration globale (seuils ITU/ETSI)
‚îÇ   ‚îú‚îÄ‚îÄ .env                        # Variables d'environnement (DATABASE_URL)
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances Python
‚îÇ   ‚îî‚îÄ‚îÄ README.md                   # Documentation utilisateur
‚îÇ
‚îú‚îÄ‚îÄ üìÑ PAGES STREAMLIT (pages/)
‚îÇ   ‚îú‚îÄ‚îÄ 1_üìä_Dashboard.py           # Visualisation KPI temps r√©el
‚îÇ   ‚îú‚îÄ‚îÄ 2_üö®_Alertes.py             # Gestion alertes syst√®me
‚îÇ   ‚îú‚îÄ‚îÄ 3_üí¨_Chatbot.py             # Assistant IA conversationnel
‚îÇ   ‚îî‚îÄ‚îÄ 4_üì§_Import.py              # Import CSV/Excel
‚îÇ
‚îú‚îÄ‚îÄ ‚öôÔ∏è BACKEND (backend/)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üóÑÔ∏è database/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ connection.py           # Gestionnaire connexion MySQL
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py               # 7 mod√®les SQLAlchemy ORM
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üîê security/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auth.py                 # Authentification bcrypt, gestion r√¥les
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìä analytics/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kpi_calculator.py       # Calculs KPI (RSSI, SNR, BER, disponibilit√©)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trend_analyzer.py       # Analyse tendances, corr√©lations
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ü§ñ ai_engine/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ anomaly_detector.py     # D√©tection anomalies (Z-score, Isolation Forest)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predictor.py            # Pr√©dictions ML (Linear Regression)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üö® alerts/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ alert_engine.py         # Moteur alertes, v√©rification seuils
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üí¨ chatbot/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ intent_recognizer.py    # Reconnaissance intention NLP
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ response_generator.py   # G√©n√©ration r√©ponses XAI
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üì• ingestion/
‚îÇ       ‚îî‚îÄ‚îÄ data_loader.py          # Import CSV/Excel, validation sch√©ma
‚îÇ
‚îú‚îÄ‚îÄ üìä DATA (data/)
‚îÇ   ‚îî‚îÄ‚îÄ scenario_*.csv              # Fichiers CSV de test
‚îÇ
‚îú‚îÄ‚îÄ üß™ TESTS (tests/)
‚îÇ   ‚îî‚îÄ‚îÄ test_*.py                   # Tests unitaires
‚îÇ
‚îî‚îÄ‚îÄ üêç ENVIRONNEMENT
    ‚îú‚îÄ‚îÄ venv311/                    # Environnement Python 3.11
    ‚îú‚îÄ‚îÄ setup_venv_py311.ps1        # Script installation automatique
    ‚îî‚îÄ‚îÄ test_mysql.py               # Script test connexion DB
```

---

## üóÑÔ∏è SCH√âMA BASE DE DONN√âES

### Table `utilisateurs`
```sql
CREATE TABLE utilisateurs (
    id INT PRIMARY KEY AUTO_INCREMENT,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    role ENUM('ADMIN', 'TECH', 'GUEST') DEFAULT 'GUEST',
    nom_complet VARCHAR(255),
    actif BOOLEAN DEFAULT TRUE,
    date_creation DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

**R√¥les** :
- **ADMIN** : Acc√®s complet (Dashboard, Alertes, Chatbot, Import)
- **TECH** : Supervision (Dashboard, Alertes, Chatbot)
- **GUEST** : Lecture seule (Dashboard uniquement)

### Table `fh_links`
```sql
CREATE TABLE fh_links (
    id INT PRIMARY KEY AUTO_INCREMENT,
    nom VARCHAR(255) UNIQUE NOT NULL,
    site_a VARCHAR(255) NOT NULL,
    site_b VARCHAR(255) NOT NULL,
    frequence_ghz FLOAT NOT NULL,
    distance_km FLOAT NOT NULL,
    actif BOOLEAN DEFAULT TRUE,
    date_creation DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

**Exemple** : "Si√®ge CNPS - Datacenter Kennedy" (23 GHz, 12.5 km)

### Table `mesures_kpi`
```sql
CREATE TABLE mesures_kpi (
    id INT PRIMARY KEY AUTO_INCREMENT,
    link_id INT NOT NULL,
    timestamp DATETIME NOT NULL,
    rssi_dbm FLOAT NOT NULL,
    snr_db FLOAT NOT NULL,
    ber FLOAT NOT NULL,
    acm_modulation VARCHAR(50),
    rainfall_mm FLOAT DEFAULT 0,
    latency_ms FLOAT DEFAULT 0,
    packet_loss FLOAT DEFAULT 0,
    FOREIGN KEY (link_id) REFERENCES fh_links(id),
    UNIQUE KEY idx_link_timestamp (link_id, timestamp)
);
```

**M√©triques cl√©s** :
- `rssi_dbm` : Received Signal Strength Indicator (dBm)
- `snr_db` : Signal-to-Noise Ratio (dB)
- `ber` : Bit Error Rate (sans unit√©, ex: 1e-8)
- `acm_modulation` : Adaptive Coding Modulation (64QAM, 32QAM, 16QAM)

### Table `alertes`
```sql
CREATE TABLE alertes (
    id INT PRIMARY KEY AUTO_INCREMENT,
    link_id INT NOT NULL,
    timestamp DATETIME NOT NULL,
    type VARCHAR(100) NOT NULL,
    severite ENUM('CRITIQUE', 'MAJEURE', 'MINEURE', 'WARNING', 'INFO', 'PREDICTIVE', 'SECURITY'),
    message TEXT NOT NULL,
    recommandation TEXT,
    resolved BOOLEAN DEFAULT FALSE,
    valeur_mesuree FLOAT,
    seuil_declenche FLOAT,
    ia_generated BOOLEAN DEFAULT FALSE,
    resolved_at DATETIME,
    resolved_by VARCHAR(255),
    FOREIGN KEY (link_id) REFERENCES fh_links(id)
);
```

**Types d'alertes** :
- `RSSI_DEGRADED`, `RSSI_CRITICAL` : Puissance signal faible
- `SNR_LOW`, `SNR_CRITICAL` : Bruit √©lev√©
- `BER_HIGH`, `BER_UNACCEPTABLE` : Taux d'erreur √©lev√©
- `LATENCY_HIGH` : Latence anormale
- `PACKET_LOSS_HIGH` : Perte de paquets
- `ANOMALY_DETECTED` : Anomalie d√©tect√©e par IA
- `PREDICTION_DEGRADATION` : Pr√©diction de panne

### Table `kpi_syntheses`
```sql
CREATE TABLE kpi_syntheses (
    id INT PRIMARY KEY AUTO_INCREMENT,
    link_id INT NOT NULL,
    date DATE NOT NULL,
    rssi_avg FLOAT,
    rssi_min FLOAT,
    rssi_max FLOAT,
    snr_avg FLOAT,
    snr_min FLOAT,
    snr_max FLOAT,
    ber_avg FLOAT,
    ber_max FLOAT,
    disponibilite FLOAT,
    etat_global VARCHAR(50),
    nb_alertes INT DEFAULT 0,
    FOREIGN KEY (link_id) REFERENCES fh_links(id),
    UNIQUE KEY idx_link_date (link_id, date)
);
```

**Usage** : Synth√®se journali√®re automatique, historique long terme

### Table `traces_connexion`
```sql
CREATE TABLE traces_connexion (
    id INT PRIMARY KEY AUTO_INCREMENT,
    user_id INT NOT NULL,
    timestamp DATETIME NOT NULL,
    action VARCHAR(100),
    ip_address VARCHAR(50),
    user_agent TEXT,
    FOREIGN KEY (user_id) REFERENCES utilisateurs(id)
);
```

**Usage** : Audit s√©curit√©, tra√ßabilit√© actions

### Table `parametres_systeme`
```sql
CREATE TABLE parametres_systeme (
    id INT PRIMARY KEY AUTO_INCREMENT,
    cle VARCHAR(255) UNIQUE NOT NULL,
    valeur TEXT,
    description TEXT,
    type_valeur VARCHAR(50),
    date_modification DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);
```

**Usage** : Configuration dynamique, seuils personnalisables

---

## üîÑ FLUX DE DONN√âES

### 1. Authentification
```
[Utilisateur] ‚Üí app.py ‚Üí backend/security/auth.py
                              ‚Üì
                       authenticate_user()
                              ‚Üì
                     V√©rification bcrypt
                              ‚Üì
                    Session Streamlit cr√©√©e
                              ‚Üì
              st.session_state['authenticated'] = True
              st.session_state['user'] = User object
```

### 2. Dashboard - Affichage m√©triques
```
[Dashboard.py] ‚Üí get_latest_kpis(link_id)
                        ‚Üì
                backend/analytics/kpi_calculator.py
                        ‚Üì
               Query: SELECT * FROM mesures_kpi 
                      WHERE link_id = ? 
                      ORDER BY timestamp DESC LIMIT 1
                        ‚Üì
               calculate_link_status(rssi, snr, ber)
                        ‚Üì
               Return: {'rssi_dbm': -65, 'etat_global': 'DEGRADED', ...}
                        ‚Üì
                [Affichage Streamlit]
```

### 3. Dashboard - Graphiques avec filtre p√©riode
```
[Dashboard.py] ‚Üí Utilisateur s√©lectionne "12 heures"
                        ‚Üì
              date_from = utcnow() - timedelta(hours=12)
                        ‚Üì
              Query: SELECT * FROM mesures_kpi 
                     WHERE link_id = ? AND timestamp >= ?
                     ORDER BY timestamp
                        ‚Üì
              Conversion en dictionnaires (dans session DB)
                        ‚Üì
              DataFrame pandas ‚Üí Plotly graphs
```

### 4. Alertes - V√©rification automatique
```
[Alertes.py] ‚Üí Clic "V√©rifier Alertes"
                        ‚Üì
              backend/alerts/alert_engine.py
                        ‚Üì
              check_and_create_alerts(link_id)
                        ‚Üì
              R√©cup√©ration derni√®re mesure KPI
                        ‚Üì
              Si RSSI < -75 dBm ‚Üí create_alert('RSSI_CRITICAL')
              Si SNR < 12 dB ‚Üí create_alert('SNR_LOW')
              Si BER > 1e-5 ‚Üí create_alert('BER_HIGH')
                        ‚Üì
              INSERT INTO alertes (...)
                        ‚Üì
              Return: [Liste nouvelles alertes]
```

### 5. Chatbot - R√©ponse XAI
```
[Chatbot.py] ‚Üí Utilisateur tape "Quel est l'√©tat de la liaison ?"
                        ‚Üì
              backend/chatbot/intent_recognizer.py
                        ‚Üì
              recognize_intent(message) ‚Üí 'link_status'
                        ‚Üì
              backend/chatbot/response_generator.py
                        ‚Üì
              get_link_status_response(link_id)
                        ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ 1. get_latest_kpis(link_id)     ‚îÇ
              ‚îÇ 2. calculate_period_statistics() ‚îÇ
              ‚îÇ 3. get_active_alerts(link_id)   ‚îÇ
              ‚îÇ 4. detect_anomalies_zscore()    ‚îÇ
              ‚îÇ 5. predict_next_values()        ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
              G√©n√©ration r√©ponse format√©e avec :
              - M√©triques actuelles
              - Statistiques 24h
              - Diagnostic IA (cause + confiance)
              - Recommandations ITU
              - Pr√©dictions 2h
                        ‚Üì
              Return: Texte format√© markdown
                        ‚Üì
              [Affichage bulle chatbot]
```

### 6. Import - CSV vers DB
```
[Import.py] ‚Üí Upload CSV file
                        ‚Üì
              backend/ingestion/data_loader.py
                        ‚Üì
              validate_csv_schema(df)
                        ‚Üì
              Si colonnes manquantes ‚Üí Erreur
              Si OK ‚Üí load_measures_from_dataframe(df, link_id)
                        ‚Üì
              Pour chaque ligne :
                  ‚îú‚îÄ V√©rifier doublon (link_id + timestamp)
                  ‚îú‚îÄ Si nouveau ‚Üí INSERT INTO mesures_kpi
                  ‚îî‚îÄ Si doublon ‚Üí Ignorer
                        ‚Üì
              Return: (nb_import√©es, nb_doublons)
                        ‚Üì
              [Affichage statistiques]
```

---

## ü§ñ INTELLIGENCE ARTIFICIELLE

### 1. D√©tection d'anomalies (Z-score)

**Fichier** : `backend/ai_engine/anomaly_detector.py`

**Algorithme** :
```python
# 1. R√©cup√©rer mesures des 48h
measures = query(MesureKPI).filter(timestamp >= date_from).all()
values = [m.rssi_dbm for m in measures]

# 2. Calculer Z-score
mean = np.mean(values)
std = np.std(values)
z_scores = [(v - mean) / std for v in values]

# 3. D√©tecter anomalies (|z| > 3)
anomalies = [m for i, m in enumerate(measures) if abs(z_scores[i]) > 3]
```

**Seuil** : 3 √©carts-types (config `IA_CONFIG['anomaly_threshold']`)

### 2. Pr√©dictions (R√©gression lin√©aire)

**Fichier** : `backend/ai_engine/predictor.py`

**Algorithme** :
```python
from sklearn.linear_model import LinearRegression

# 1. Donn√©es d'entra√Ænement (48h)
X = [[i] for i in range(len(measures))]  # Index temporel
y = [m.rssi_dbm for m in measures]       # Valeurs RSSI

# 2. Entra√Ænement
model = LinearRegression()
model.fit(X, y)

# 3. Pr√©diction 2h (8 points √† 15 min)
future_X = [[len(measures) + i] for i in range(8)]
predictions = model.predict(future_X)

# 4. Calcul confiance (R¬≤ score)
r2 = model.score(X, y)
confidence = max(0, min(100, r2 * 100))
```

**Horizon** : 2 heures (configurable dans `config.IA_CONFIG`)

### 3. D√©tection chutes brutales

**Fichier** : `backend/ai_engine/anomaly_detector.py`

**Algorithme** :
```python
drops = []
for i in range(1, len(measures)):
    delta = measures[i].rssi_dbm - measures[i-1].rssi_dbm
    if delta < -10:  # Chute > 10 dBm
        drops.append({
            'timestamp': measures[i].timestamp,
            'drop': delta,
            'from': measures[i-1].rssi_dbm,
            'to': measures[i].rssi_dbm
        })
```

**Usage** : D√©tection coupures, interf√©rences

### 4. Analyse corr√©lation pluie-RSSI

**Fichier** : `backend/analytics/trend_analyzer.py`

**Algorithme** :
```python
import pandas as pd

# 1. Cr√©er DataFrame
df = pd.DataFrame([{
    'rssi': m.rssi_dbm,
    'rain': m.rainfall_mm
} for m in measures])

# 2. Calcul corr√©lation Pearson
correlation = df['rssi'].corr(df['rain'])

# 3. Interpr√©tation
if correlation < -0.7:
    strength = "forte corr√©lation n√©gative"
elif correlation < -0.4:
    strength = "corr√©lation mod√©r√©e"
else:
    strength = "faible corr√©lation"
```

**R√©f√©rence ITU** : ITU-R P.530 (att√©nuation par pr√©cipitations)

---

## üîê S√âCURIT√â

### 1. Authentification
- **Hashing** : bcrypt (12 rounds, salt automatique)
- **Session** : Streamlit `st.session_state` (c√¥t√© serveur)
- **Timeout** : 3600 secondes (1h, configurable)

### 2. Contr√¥le d'acc√®s (RBAC)

**Fichier** : `backend/security/auth.py`

```python
ROLE_PERMISSIONS = {
    'ADMIN': ['all'],
    'TECH': ['view', 'resolve_alerts', 'chat'],
    'GUEST': ['view']
}

def check_permission(user, required_permissions):
    if user.role == 'ADMIN':
        return True
    return any(perm in ROLE_PERMISSIONS[user.role] for perm in required_permissions)
```

**Usage dans pages** :
```python
# Import.py (ligne 19)
if st.session_state.user.role != 'ADMIN':
    st.error("‚ùå Acc√®s refus√© - R√©serv√© aux administrateurs")
    st.stop()
```

### 3. Validation donn√©es
- **Schema CSV** : Colonnes obligatoires v√©rifi√©es
- **Plages valeurs** : Respect limites physiques ITU
- **SQL Injection** : Protection par SQLAlchemy ORM (param√©trage automatique)

---

## üìä SEUILS ITU/ETSI

**Fichier** : `config.py`

### RSSI (Received Signal Strength Indicator)
```python
SEUILS_RSSI = {
    'EXCELLENT': -50,   # > -50 dBm : Signal tr√®s fort
    'BON': -60,         # -50 √† -60 : Signal fort
    'ACCEPTABLE': -70,  # -60 √† -70 : Signal correct
    'DEGRADED': -75,    # -70 √† -75 : Signal faible
    'CRITIQUE': -80     # < -80 : Signal critique
}
```

**R√©f√©rence** : ITU-R P.530-17 (Propagation data for FH links)

### SNR (Signal-to-Noise Ratio)
```python
SEUILS_SNR = {
    'EXCELLENT': 30,    # > 30 dB : Excellent
    'BON': 20,          # 20-30 dB : Bon
    'ACCEPTABLE': 15,   # 15-20 dB : Acceptable
    'DEGRADED': 10,     # 10-15 dB : D√©grad√©
    'CRITIQUE': 5       # < 5 dB : Critique
}
```

**R√©f√©rence** : ETSI EN 302 217 (Fixed Radio Systems)

### BER (Bit Error Rate)
```python
SEUILS_BER = {
    'EXCELLENT': 1e-9,   # < 10‚Åª‚Åπ : Excellent
    'BON': 1e-7,         # 10‚Åª‚Åπ √† 10‚Åª‚Å∑ : Bon
    'ACCEPTABLE': 1e-6,  # 10‚Åª‚Å∑ √† 10‚Åª‚Å∂ : Acceptable
    'DEGRADED': 1e-5,    # 10‚Åª‚Å∂ √† 10‚Åª‚Åµ : D√©grad√©
    'CRITIQUE': 1e-4     # > 10‚Åª‚Å¥ : Critique
}
```

**R√©f√©rence** : ITU-T G.826 (Error performance parameters)

### Disponibilit√©
```python
SEUILS_DISPONIBILITE = {
    'EXCELLENT': 99.999,  # 5 nines : 5.26 min/an indispo
    'BON': 99.99,         # 4 nines : 52.6 min/an
    'ACCEPTABLE': 99.9,   # 3 nines : 8.76 h/an
    'DEGRADED': 99.0,     # 2 nines : 87.6 h/an
    'CRITIQUE': 95.0      # < 95% : Inacceptable
}
```

**R√©f√©rence** : ITU-T G.827 (Availability objectives)

---

## üé® INTERFACE UTILISATEUR

### Design System

**Couleurs** :
- Bleu primaire : `#3B82F6` (liens, graphiques)
- Bleu fonc√© : `#1E3A8A` (header)
- Vert : `#10B981` (√©tat NORMAL)
- Orange : `#FFA500` (√©tat DEGRADED)
- Rouge : `#DC143C` (√©tat CRITIQUE)

**Badges r√¥les** :
- üî¥ ADMIN : Rouge
- üü° TECH : Jaune
- üü¢ GUEST : Vert

### Pages Streamlit

**app.py** (Accueil) :
- Authentification (email/password)
- S√©lection liaison FH
- Aper√ßu statistiques
- Navigation vers pages

**Dashboard** :
- 5 m√©triques principales (cards)
- 4 m√©triques secondaires
- 3 graphiques Plotly interactifs
- Filtre p√©riode (6/12/24/48/72h)
- Statistiques d√©taill√©es

**Alertes** :
- Statistiques s√©v√©rit√© (5 colonnes)
- 3 filtres (s√©v√©rit√©, statut, p√©riode)
- Cartes alertes avec ic√¥nes
- Boutons r√©soudre/supprimer (r√¥le)
- Graphique pie chart r√©partition

**Chatbot** :
- 6 suggestions initiales (disparaissent)
- Bulles WhatsApp-style
- Auto-scroll
- Historique session
- R√©ponses XAI dynamiques

**Import** :
- File uploader (CSV/Excel)
- Validation sch√©ma temps r√©el
- Aper√ßu DataFrame
- Statistiques import
- Gestion doublons

---

## üöÄ D√âPLOIEMENT

### Pr√©requis
1. **Python 3.11** (recommand√© pour stabilit√©)
2. **MySQL 8.0+** (Laragon, XAMPP, ou serveur distant)
3. **Git** (optionnel)

### Installation

```powershell
# 1. Cloner/t√©l√©charger le projet
cd "C:\Users\FTAB TECH\Desktop\netpulse-ai"

# 2. Cr√©er environnement virtuel Python 3.11
python -m venv venv311
.\venv311\Scripts\Activate.ps1

# 3. Installer d√©pendances
pip install -r requirements.txt

# 4. Configurer base de donn√©es (.env)
DATABASE_URL=mysql+pymysql://root:@localhost:3306/netpulse_ai
SECRET_KEY=your_secret_key_here
SESSION_TIMEOUT=3600
ENVIRONMENT=development

# 5. Cr√©er base de donn√©es
python setup_mysql.py

# 6. Importer donn√©es de test
python import_scenario.py

# 7. Lancer l'application
streamlit run app.py
```

### Configuration production

**Variables d'environnement** :
```bash
DATABASE_URL=mysql+pymysql://user:password@prod-server:3306/netpulse_ai
SECRET_KEY=<cl√©_al√©atoire_forte_256_bits>
SESSION_TIMEOUT=1800
ENVIRONMENT=production
```

**S√©curit√©** :
- SSL/TLS pour MySQL
- HTTPS pour Streamlit (reverse proxy Nginx)
- Firewall MySQL (port 3306)
- Backup quotidien base de donn√©es

**Performance** :
- Index sur `mesures_kpi(link_id, timestamp)`
- Partitionnement table `mesures_kpi` par mois
- Cache Redis pour KPI fr√©quents
- CDN pour assets statiques

---

## üìà √âVOLUTIONS FUTURES

### Fonctionnalit√©s planifi√©es
- [ ] API REST (FastAPI) pour int√©gration externe
- [ ] Notifications email/SMS pour alertes critiques
- [ ] Dashboard multi-liaisons (vue agr√©g√©e)
- [ ] Export PDF rapports mensuels
- [ ] Mod√®les ML avanc√©s (LSTM pour s√©ries temporelles)
- [ ] Cartographie r√©seau avec Leaflet/Mapbox
- [ ] WebSockets pour mises √† jour temps r√©el
- [ ] Module gestion incidents (ticketing)
- [ ] Int√©gration m√©t√©o (API OpenWeatherMap)
- [ ] Logs structur√©s (ELK stack)

### Optimisations techniques
- [ ] Migration vers PostgreSQL (TimescaleDB pour time-series)
- [ ] Impl√©mentation cache Redis
- [ ] Tests unitaires complets (pytest)
- [ ] CI/CD avec GitHub Actions
- [ ] Dockerisation (Docker Compose)
- [ ] Monitoring avec Prometheus/Grafana
- [ ] Documentation API avec Swagger

---

## üìö R√âF√âRENCES

### Standards ITU/ETSI
- **ITU-R P.530-17** : Propagation data for terrestrial FH systems
- **ITU-T G.826** : Error performance parameters for digital links
- **ITU-T G.827** : Availability performance parameters
- **ETSI EN 302 217** : Fixed Radio Systems characteristics

### Documentation technique
- **Streamlit** : https://docs.streamlit.io
- **SQLAlchemy** : https://docs.sqlalchemy.org
- **Scikit-learn** : https://scikit-learn.org/stable/
- **Plotly** : https://plotly.com/python/

### Contact
- **Projet** : NetPulse-AI v1.0.0
- **Date** : Novembre 2025
- **Licence** : Propri√©taire (usage acad√©mique autoris√©)

---

**FIN DU DOCUMENT ARCHITECTURE** üèóÔ∏è
